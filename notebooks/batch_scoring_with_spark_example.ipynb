{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Scoring with PySpark Example"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "import pandas as pd"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "spark = SparkSession.builder.appName('BridgeBatchScoring').getOrCreate()"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.read_csv('../data/processed/features.csv')\n",
    "features = [col for col in df.columns if col not in ['structure_id', 'failure_within_1yr']]\n",
    "spark_df = spark.createDataFrame(df[features + ['structure_id']])"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble Features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "vec_assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "spark_df = vec_assembler.transform(spark_df)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model (Spark MLlib Format)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Assume model was exported to Spark MLlib format previously as ../models/trained/spark_rf_model\n",
    "model = RandomForestClassificationModel.load('../models/trained/spark_rf_model')"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scored = model.transform(spark_df)\n",
    "scored.select('structure_id', 'probability', 'prediction').show(5)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scored.select('structure_id', 'probability', 'prediction').toPandas().to_csv('../models/evaluation/spark_batch_predictions.csv', index=False)\n",
    "print('Batch scoring with Spark complete.')"
   ],
   "execution_count": 7,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}